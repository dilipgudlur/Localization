Humans can localise sound into three different coordinate systems. The 'azimuth' or left/right coordinate is calculated by the brain using the difference between time of arrival of a sound in each ear, as well as the distorting effects of the head and shoulders on sound waves (Goldstein, 2002). For some sounds, such as very low, or pure tones, we are very poor at spatial localisation. However, as speech and hearing co-evolved, we are best at localising complex sounds above 300Hz (Sivian and White)
'Elevation' - or up/down - localisation cannot rely on comparisons between the two ears. Instead, the brain relies on "spectral cues". The unique shape of your pinnae (the funny folds in your ear) act to change the 'shape' of incoming soundwaves depending on their incoming angle. There is research that shows that if an individual’s pinnae are altered (for example, by taping them flat, or placing tubes into your ear canal), it actually changes their auditory perceptions (Van Hoesel, 2003).
However, to answer your question, often the most difficult location for the brain to interpret is whether a sound is coming from in front of or behind the individual (Johngkees and Groen). When tests are done with pure tones, very often a sound originating from behind us is perceived as if coming from the same angle in front. The primary method by which the brain determines whether a sound is coming from in front or behind the listener is again through distortions caused by the pinnae. Simply, because the human ear faces forward, these distortions do not occur when the sound originates behind the head. Interestingly, because of this, sounds lacking this information (as in most microphone recordings) tend to be localized toward the back of the listener when heard over headphones. Additionally, for all of the spatial hearing, reflection plays a major part. If a sound has a very clear start, then the difference between the effects of the first wave and the second (reflected) wave can provide key information in localising a sound in space.
Overall, though accurate sound localisation is “one of the most complicated processes performed by the brain” given the appropriate cues, the brain can detect the direction of a sound source with an accuracy of up to 2 degrees. It is interesting to note that the primary warning tones used in society are more pure tones than complex ones. Examples include fire alarms, police sirens, mobile phone alerts, alarm clocks, etc... Thus, these “devices which are supposed to help us localise sounds do not possess the acoustic complexity necessary for accurate localisation” (Edward Boas).
Sources: http://www.sfu.ca/sonic-studio/handbook/Pinna.html http://jeb.biologists.org/cgi/reprint/210/22/3990.pdf http://journals.lww.com/otology-neurotology/pages/articleviewer.aspx?year=2005&issue=01000&article=00023&type=abstract http://www.jstor.org/stable/93054?seq=4 http://www.stanford.edu/~boas/science/sound_direction/
